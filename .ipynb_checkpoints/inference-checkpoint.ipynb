{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacotron 2 inference code \n",
    "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "UsageError: Line magic function `%matpltolib` not found.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "# sys.path.append('waveglow\n",
    "                \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "# from layers import TacotronSTFT\n",
    "# from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "import pickle\n",
    "from scipy.stats import pearsonr\n",
    "%matpltolib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
    "                       interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/checkpoint_35000\"\n",
    "model = load_model(hparams)\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_var/test_new_phoneme', 'rb') as handle:\n",
    "    test_phoneme= pickle.loads(handle.read())\n",
    "    \n",
    "with open('new_var/test_new_ema', 'rb') as handle:\n",
    "    test_ema= pickle.loads(handle.read())\n",
    "    \n",
    "with open('new_var/test_ema_len', 'rb') as handle:\n",
    "    test_ema_len= pickle.loads(handle.read())\n",
    "    \n",
    "test_phoneme = np.array(test_phoneme)\n",
    "test_ema = np.array(test_ema)\n",
    "test_ema_len = np.array(test_ema_len)\n",
    "\n",
    "with open('new_var/train_new_phoneme', 'rb') as handle:\n",
    "    train_phoneme= pickle.loads(handle.read())\n",
    "    \n",
    "with open('new_var/train_new_ema', 'rb') as handle:\n",
    "    train_ema= pickle.loads(handle.read())\n",
    "    \n",
    "    \n",
    "with open('new_var/train_ema_len', 'rb') as handle:\n",
    "    train_ema_len= pickle.loads(handle.read())\n",
    "    \n",
    "\n",
    "    \n",
    "train_phoneme = np.array(train_phoneme)\n",
    "train_ema = np.array(train_ema)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(test_phoneme)).cuda().long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text input and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is this getting executed\n",
      "Warning! Reached max decoder steps\n"
     ]
    }
   ],
   "source": [
    "mel_outputs, mel_outputs_postnet, alignments = model.inference(sequence)\n",
    "plot_data((mel_outputs.data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.data.cpu().numpy()[0],\n",
    "           alignments.data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mel_outputs.cpu().detach().numpy()\n",
    "postnet_output = mel_outputs_postnet.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 466, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(postnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = []\n",
    "\n",
    "for i in test_ema_len:\n",
    "    check.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "noo, point= 8, 11\n",
    "\n",
    "plt.plot(output[noo,:check[noo],point])\n",
    "plt.xlabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(test_ema[noo,:check[noo],point])\n",
    "plt.xlabel('Actual Output')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(output[noo,:,point])\n",
    "plt.xlabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(test_ema[noo,:,point])\n",
    "plt.xlabel('Actual Output')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(pearsonr(test_ema[noo,:,11],translation[noo,:,11])[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6011370355027773\n",
      "0.024994229064714293\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "avg=0.0\n",
    "for i in range(test_ema.shape[0]):\n",
    "    for j in range(test_ema.shape[2]):\n",
    "        avg+=pearsonr(test_ema[i,:,j],output[i,:,j])[0]\n",
    "        count+=1\n",
    "avg=float(avg/count)\n",
    "\n",
    "print(avg)\n",
    "\n",
    "\n",
    "count=0\n",
    "avg=0.0\n",
    "for i in range(test_ema.shape[0]):\n",
    "    for j in range(test_ema.shape[2]):\n",
    "        avg+=pearsonr(test_ema[i,:check[i],j],output[i,:check[i],j])[0]\n",
    "        count+=1\n",
    "avg=float(avg/count)\n",
    "\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(train_phoneme)).cuda().long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text input and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is this getting executed\n",
      "Warning! Reached max decoder steps\n"
     ]
    }
   ],
   "source": [
    "mel_outputs, mel_outputs_postnet, alignments = model.inference(sequence)\n",
    "plot_data((mel_outputs.data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.data.cpu().numpy()[0],\n",
    "           alignments.data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mel_outputs.cpu().detach().numpy()\n",
    "postnet_output = mel_outputs_postnet.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 466, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(postnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = []\n",
    "\n",
    "for i in train_ema_len:\n",
    "    check.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "noo, point= 1, 5\n",
    "\n",
    "plt.plot(output[noo,:check[noo],point])\n",
    "plt.xlabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(train_ema[noo,:check[noo],point])\n",
    "plt.xlabel('Actual Output')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(output[noo,:,point])\n",
    "plt.xlabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(train_ema[noo,:,point])\n",
    "plt.xlabel('Actual Output')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(pearsonr(test_ema[noo,:,11],translation[noo,:,11])[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6344332404548146\n",
      "0.18710909874481876\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "avg=0.0\n",
    "for i in range(train_ema.shape[0]):\n",
    "    for j in range(train_ema.shape[2]):\n",
    "        avg+=pearsonr(train_ema[i,:,j],output[i,:,j])[0]\n",
    "        count+=1\n",
    "avg=float(avg/count)\n",
    "\n",
    "print(avg)\n",
    "\n",
    "\n",
    "count=0\n",
    "avg=0.0\n",
    "for i in range(train_ema.shape[0]):\n",
    "    for j in range(train_ema.shape[2]):\n",
    "        avg+=pearsonr(train_ema[i,:check[i],j],output[i,:check[i],j])[0]\n",
    "        count+=1\n",
    "avg=float(avg/count)\n",
    "\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
